{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "\n",
    "#Includes ghost points for the periodic boundary condition\n",
    "Nx = 203\n",
    "Ny = 203\n",
    "\n",
    "#grid size\n",
    "hx = 1/(Nx-3)\n",
    "hy = 1/(Ny-3)\n",
    "\n",
    "e = 0.02\n",
    "\n",
    "#domain size\n",
    "xmin = 0.1\n",
    "xmax = 1.0\n",
    "ymin = 0.0\n",
    "ymax = 1.0\n",
    "\n",
    "#weight \n",
    "omega = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function considers all the inner points and organize the nodal values for the calculation of e\n",
    "def organize_interaction(A):\n",
    "\n",
    "    first = tf.concat([tf.reshape(A[1:, 1:-1], (-1, 1)), tf.reshape(A[0:-1, 1:-1], (-1, 1))], axis=1)\n",
    "    \n",
    "    second = tf.concat([tf.reshape(A[1:-1, 1:], (-1, 1)), tf.reshape(A[1:-1, 0:-1], (-1, 1))], axis=1)\n",
    "\n",
    "    input = tf.concat([first, second], axis=0)\n",
    "    \n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiplying the result of f(R) with PM matrix gives c_{i,j}\n",
    "def calc_PM(Nx, Ny):\n",
    "\n",
    "    #number of divisions along x and y axes\n",
    "    m = Nx - 1\n",
    "    n = Ny - 1\n",
    "\n",
    "    num_interactions = (n-1)*m + (m-1)*n\n",
    "    num_inner_nodes = (m-1)*(n-1)\n",
    "    \n",
    "    first_gap = n-2\n",
    "    second_gap = (n-2) + (n-1)*(m-2)\n",
    "    \n",
    "    indices = np.zeros((4*num_inner_nodes, 2))\n",
    "    values = np.zeros((4*num_inner_nodes, ))\n",
    "    dense_size = np.array([num_inner_nodes, num_interactions]) \n",
    "    \n",
    "    current = 0\n",
    "    for i in range(num_inner_nodes):\n",
    "        indices[current][:] = np.array([i, i])\n",
    "        values[current] = 1.\n",
    "        current = current + 1\n",
    "        \n",
    "        indices[current][:] = np.array([i, i+1+first_gap])\n",
    "        values[current] = -1.\n",
    "        current = current + 1\n",
    "\n",
    "        indices[current][:] = np.array([i, i+1+first_gap+1+second_gap + int(i/(n-1))])\n",
    "        values[current] = 1.\n",
    "        current = current + 1\n",
    "\n",
    "        indices[current][:] = np.array([i, i+1+first_gap+1+second_gap+1 + int(i/(n-1))])\n",
    "        values[current] = -1.\n",
    "        current = current + 1\n",
    "\n",
    "    values = tf.convert_to_tensor(values, dtype='float32')\n",
    "    \n",
    "    PM = tf.sparse.SparseTensor(indices, values, dense_size)\n",
    "    \n",
    "    return PM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, nhu=2, npl=32):\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    model.add(tf.keras.layers.Input(input_shape))\n",
    "\n",
    "    for _ in range(nhu):\n",
    "        model.add(tf.keras.layers.Dense(npl, \n",
    "                                        activation='relu',\n",
    "                                        #kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01)))\n",
    "                                        kernel_initializer='glorot_normal'))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(1, activation='tanh'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshapes A into (Nx-2)*(Ny-2) matrix and update the ghost points\n",
    "def reshape_output(Nx, Ny, A):\n",
    "    A = tf.reshape(A, (Nx-2, Ny-2))\n",
    "    \n",
    "    #adding boundary points\n",
    "    #top and buttom in the xy plane\n",
    "    top = A[:, 1:2]\n",
    "    bottom = A[:, -2:-1]\n",
    "    \n",
    "    A = tf.concat([bottom, A, top], axis=1)\n",
    "    \n",
    "    left = A[-2:-1, :]\n",
    "    right = A[1:2, :]\n",
    "    \n",
    "    A = tf.concat([left, A, right], axis=0)\n",
    "\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to compute the energy from integral\n",
    "def compute_energy(phi):\n",
    "    grad2 = tf.math.square(phi[1:-1, 2:] - phi[1:-1, 0:-2])/(4.0*hx*hx) \\\n",
    "            + tf.math.square(phi[2:, 1:-1] - phi[0:-2, 1:-1])/(4.0*hy*hy)\n",
    "            \n",
    "    integral = 0.5*grad2 + (1/e**2)*0.25*tf.math.square(tf.math.square(phi[1:-1, 1:-1]) - 1)\n",
    "\n",
    "    #riemann sum\n",
    "    energy = tf.reduce_sum(hx*hy*integral)\n",
    "    \n",
    "    return energy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algorithm 2 from the paper\n",
    "#M is the number of message passing steps\n",
    "#fR and fO are the networks\n",
    "def march_forward(M, phi_in, fR, fO, PM):\n",
    "\n",
    "    Nx = phi_in.shape[0]\n",
    "    Ny = phi_in.shape[1]\n",
    "    \n",
    "    H = tf.zeros(phi_in.shape, dtype='float32')\n",
    "    \n",
    "    for _ in range(M):\n",
    "        input_phi = organize_interaction(phi_in)\n",
    "        input_H = organize_interaction(H)\n",
    "        input1 = tf.concat([input_phi, input_H], axis=1)\n",
    "\n",
    "        \n",
    "        output1 = fR(input1)\n",
    "\n",
    "        c = tf.sparse.sparse_dense_matmul(PM, output1)\n",
    "        \n",
    "        input2 = tf.concat((tf.reshape(phi_in[1:-1, 1:-1], (-1, 1)), c), axis=1)\n",
    "        \n",
    "        output2 = fO(input2)\n",
    "        \n",
    "        H = reshape_output(Nx, Ny, output2)\n",
    "    \n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(M, phi_in, fR, fO, PM, initial=False):\n",
    "    phi_out = march_forward(M, phi_in, fR, fO, PM)\n",
    "    \n",
    "    energy_in = compute_energy(phi_in)\n",
    "    energy_out = compute_energy(phi_out)\n",
    "    \n",
    "    if initial:\n",
    "        loss = tf.reduce_mean(tf.math.square(phi_in - phi_out))\n",
    "    else:\n",
    "        loss = tf.math.reduce_mean(tf.math.square(phi_out - phi_in)) + omega*energy_out/energy_in\n",
    "    \n",
    "    return energy_in, energy_out, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_phi(Nx, Ny):\n",
    "\n",
    "    phi = np.ones((Nx, Ny))\n",
    "\n",
    "    for i in range(Nx):\n",
    "        #i-1 because we have added ghost points to store the boundary condition\n",
    "        x = 0+(i-1)*hx\n",
    "        for j in range(Ny):\n",
    "            y = 0+(j-1)*hy\n",
    "            phi[i, j] = np.sin(4*np.pi*x)*np.cos(4*np.pi*y)\n",
    "    \n",
    "    phi[0, :] = phi[-3, :]\n",
    "    phi[-1, :] = phi[2, :]\n",
    "    phi[:, 0] = phi[:, -3]\n",
    "    phi[:, -1] = phi[:, 2]\n",
    "    \n",
    "    return tf.convert_to_tensor(phi, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FONN():\n",
    "    def __init__(self, M):\n",
    "        self.M = M \n",
    "        self.PM = calc_PM(Nx, Ny)\n",
    "        \n",
    "        self.fR = create_model(input_shape=(4, ))\n",
    "        self.fO = create_model(input_shape=(2, ))\n",
    "        \n",
    "        self.phi_0 = initialize_phi(Nx, Ny)\n",
    "        self.phi = initialize_phi(Nx, Ny)\n",
    "    \n",
    "    def initial_training(self, epochs):\n",
    "        optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "        for ep in range(epochs):\n",
    "\n",
    "            noise = tf.random.normal(self.phi_0.shape, mean=0.0, stddev=0.05, dtype='float32')\n",
    "            noisy_input = self.phi_0 + noise\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                energy_in, energy_out, loss = compute_loss(self.M, noisy_input, self.fR, self.fO, self.PM, initial=True)\n",
    "            grads = tape.gradient(loss, tape.watched_variables())\n",
    "            \n",
    "            optimizer.apply_gradients(zip(grads, tape.watched_variables()))\n",
    "            del tape\n",
    "\n",
    "            print(\"epoch = \", ep, \" loss = \", loss.numpy())\n",
    "\n",
    "    \n",
    "    #K -> fine tuning steps\n",
    "    def progressive_method(self, steps, K, save_plots=False, location=\"\"):\n",
    "        optimizer = tf.keras.optimizers.Adam()\n",
    "        \n",
    "        #open the file\n",
    "        if save_plots:\n",
    "            name_E = location + \"/energy.txt\"\n",
    "            file_E = open(name_E, \"w\")\n",
    "\n",
    "        for step in range(steps):\n",
    "            \n",
    "            for ep in range(K):\n",
    "                with tf.GradientTape() as tape:\n",
    "                    energy_in, energy_out, loss = compute_loss(self.M, self.phi, self.fR, self.fO, self.PM)\n",
    "                \n",
    "                grads = tape.gradient(loss, tape.watched_variables())\n",
    "\n",
    "                optimizer.apply_gradients(zip(grads, tape.watched_variables()))\n",
    "                del tape\n",
    "\n",
    "            \n",
    "            self.phi = march_forward(self.M, self.phi, self.fR, self.fO, self.PM)\n",
    "\n",
    "            print(\"step = \", step, \" energy_in = \", energy_in.numpy(), \" energy_out = \", energy_out.numpy())\n",
    "\n",
    "            #if energy gets 0 \n",
    "            if np.abs(energy_out.numpy()) < 10e-5:\n",
    "                data_file_name = location + \"/dat_\" + str(step) + \".txt\"\n",
    "                np.savetxt(data_file_name, np.reshape(self.phi[1:-1, 1:-1].numpy(), -1))\n",
    "                fig_name = location + \"/\" + str(step) + \".pdf\"\n",
    "                title_ = \"$E(\\phi)$ = \" + str(compute_energy(self.phi).numpy())\n",
    "                plt.figure()\n",
    "                plt.contourf(tf.transpose(self.phi[1:-1, 1:-1]))\n",
    "                plt.colorbar()\n",
    "                plt.title(title_)\n",
    "                plt.savefig(fig_name)\n",
    "                plt.close()\n",
    "                break\n",
    "            \n",
    "            #To save plots and result\n",
    "            if save_plots:\n",
    "                result_E = str(energy_in.numpy()) + \"\\t\" + str(energy_out.numpy()) + \"\\n\" \n",
    "                file_E.write(result_E)\n",
    "                \n",
    "                #save figure\n",
    "                #if step % 50 == 0:\n",
    "                if True:\n",
    "                    data_file_name = location + \"/dat_\" + str(step) + \".txt\"\n",
    "                    np.savetxt(data_file_name, np.reshape(self.phi[1:-1, 1:-1].numpy(), -1))\n",
    "                    fig_name = location + \"/\" + str(step) + \".pdf\"\n",
    "                    title_ = \"$E(\\phi)$ = \" + str(compute_energy(self.phi).numpy())\n",
    "                    plt.figure()\n",
    "                    plt.contourf(tf.transpose(self.phi[1:-1, 1:-1]))\n",
    "                    plt.colorbar()\n",
    "                    plt.title(title_)\n",
    "                    plt.savefig(fig_name)\n",
    "                    plt.close()\n",
    "        \n",
    "        if save_plots == True:\n",
    "            file_E.close()\n",
    "            \n",
    "            E = np.genfromtxt(name_E, dtype='float32')\n",
    "            plt.figure()\n",
    "            plt.semilogy(E[:,0], linewidth=2)\n",
    "            plt.grid(visible=True, which='both')\n",
    "            plt.title(\"$E(\\phi)$\")\n",
    "            plt.savefig(location + \"/E.pdf\")\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FONN(2)\n",
    "\n",
    "\n",
    "location = \"./Lyapunov_Results\"\n",
    "\n",
    "if not os.path.exists(location):\n",
    "    os.makedirs(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.initial_training(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.progressive_method(steps=501, K=10, save_plots=True, location=location)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "815a983d1180f45e43b0f9e623859d6adc5008144848ba59c486e4fdc876a1b8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
